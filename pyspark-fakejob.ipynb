{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP in Pyspark's MLlib\n",
    "\n",
    "## Fake Job Posting Predictions\n",
    "\n",
    "create a system that automatically flags suspicious job postings on a dataset. \n",
    "\n",
    "#### The task\n",
    "With NLP to create an alogorthim which automatically flags suspicious posts for review. \n",
    "\n",
    "#### The data\n",
    "This dataset contains 18K job descriptions out of which about 800 are fake. The data consists of both descriptionual information and meta-information about the jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.20:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NLPProject</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff814c1ae20>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create PySpark Instance\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"NLPProject\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration and Pre-Processing\n",
    "This fase will explore and load the data, then prepare and analyze it for be used in the MLLib, the steps will be:\n",
    "- Load the .csv file\n",
    "- Check the Dataframe to see if there is: Negative Numbers, How Many Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and dependencies\n",
    "\n",
    "from pyspark.ml.feature import * #CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\n",
    "from pyspark.sql.functions import * #col, udf,regexp_replace,isnull\n",
    "from pyspark.sql.types import * #StringType,IntegerType\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# For pipeline development\n",
    "from pyspark.ml import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df =  spark.read.csv(\"Datasets/fake_job_postings.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>None</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>None</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>None</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td>None</td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                      title            location  \\\n",
       "0       1                           Marketing Intern    US, NY, New York   \n",
       "1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
       "2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
       "3       4          Account Executive - Washington DC  US, DC, Washington   \n",
       "4       5                        Bill Review Manager  US, FL, Fort Worth   \n",
       "\n",
       "  department salary_range                                    company_profile  \\\n",
       "0  Marketing         None  We're Food52, and we've created a groundbreaki...   \n",
       "1    Success         None  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2       None         None  Valor Services provides Workforce Solutions th...   \n",
       "3      Sales         None  Our passion for improving quality of life thro...   \n",
       "4       None         None  SpotSource Solutions LLC is a Global Human Cap...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
       "\n",
       "                                            benefits telecommuting  \\\n",
       "0                                               None             0   \n",
       "1  What you will get from usThrough being part of...             0   \n",
       "2                                               None             0   \n",
       "3  Our culture is anything but corporate—we have ...             0   \n",
       "4                              Full Benefits Offered             0   \n",
       "\n",
       "  has_company_logo has_questions employment_type required_experience  \\\n",
       "0                1             0           Other          Internship   \n",
       "1                1             0       Full-time      Not Applicable   \n",
       "2                1             0            None                None   \n",
       "3                1             0       Full-time    Mid-Senior level   \n",
       "4                1             1       Full-time    Mid-Senior level   \n",
       "\n",
       "  required_education                   industry              function  \\\n",
       "0               None                       None             Marketing   \n",
       "1               None  Marketing and Advertising      Customer Service   \n",
       "2               None                       None                  None   \n",
       "3  Bachelor's Degree          Computer Software                 Sales   \n",
       "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
       "\n",
       "  fraudulent  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 5 rows\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|          fraudulent|count|\n",
      "+--------------------+-----+\n",
      "|                   0|16080|\n",
      "|                   1|  886|\n",
      "|                null|  176|\n",
      "|           Full-time|   73|\n",
      "|Hospital & Health...|   55|\n",
      "|   Bachelor's Degree|   53|\n",
      "|         Engineering|   26|\n",
      "| perform quality ...|   17|\n",
      "|         Unspecified|   15|\n",
      "|    Mid-Senior level|   15|\n",
      "|               Sales|   14|\n",
      "|           Associate|   14|\n",
      "|Information Techn...|   13|\n",
      "| passionate about...|   13|\n",
      "|           Marketing|   13|\n",
      "|   Computer Software|   12|\n",
      "|            Internet|   12|\n",
      "|      Not Applicable|   11|\n",
      "|We offer an excel...|   11|\n",
      "| además con el fi...|   10|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See how many categories we have in fraudulent (should be 2)\n",
    "df.groupBy(\"fraudulent\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the fraudulents rows that is not 0 or 1\n",
    "df = df.filter(\"fraudulent == 1 OR fraudulent == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|fraudulent|count|\n",
      "+----------+-----+\n",
      "|         0|16080|\n",
      "|         1|  886|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See how many categories we have in fraudulent (should be 2)\n",
    "df.groupBy(\"fraudulent\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of rows with Null against the Total Rows: 95.72085347164918%\n"
     ]
    }
   ],
   "source": [
    "# Show how many Null we have in the Dataframe\n",
    "total_rows = df.count() \n",
    "total_drop = df.na.drop().count()\n",
    "percent_drop = (total_rows-total_drop)/total_rows*100\n",
    "print(\"Percentage of rows with Null against the Total Rows: {}%\".format(percent_drop ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cant drop all the rows with null values or will lose almost 96% of the data.\n",
    "# Lets concatenate the data that we are intrested: descrption, requirements and benefits:\n",
    "#df = df.withColumn('description', concat(col('description'),lit(\" \"),col('requirements')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description fraudulent\n",
       "0  Food52, a fast-growing, James Beard Award-winn...          0\n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...          0\n",
       "2  Our client, located in Houston, is actively se...          0\n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...          0\n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...          0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the columns that we need\n",
    "df = df.select(\"description\", \"fraudulent\")\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of rows with Null against the Total Rows: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Show how many Null we have in the new Dataframe\n",
    "total_rows = df.count() \n",
    "total_drop = df.na.drop().count()\n",
    "percent_drop = (total_rows-total_drop)/total_rows*100\n",
    "print(\"Percentage of rows with Null against the Total Rows: {}%\".format(percent_drop ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can drop the null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|fraudulent|count|\n",
      "+----------+-----+\n",
      "|0         |6427 |\n",
      "|1         |886  |\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Balance the signal, reduce the amount of 0 classification against the 1, to train better or model\n",
    "df = df.sampleBy(\"fraudulent\", fractions={'0': 0.4, '1': 1.0}, seed=10)\n",
    "# QA again \n",
    "df.groupBy(\"fraudulent\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the () and / from the description Column\n",
    "df = df.withColumn(\"description\",translate(col(\"description\"), \"/\", \" \")) \\\n",
    "        .withColumn(\"description\",translate(col(\"description\"), \"(\", \" \")) \\\n",
    "        .withColumn(\"description\",translate(col(\"description\"), \")\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Remove any special character\n",
    "# Removing anything that is not a letter\n",
    "df = df.withColumn(\"description\",regexp_replace(col('description'), '[^A-Za-z ]+', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove multiple spaces\n",
    "df = df.withColumn(\"description\",regexp_replace(col('description'), ' +', ' '))\n",
    "\n",
    "# Lower Case all words\n",
    "df = df.withColumn(\"description\",lower(col('description')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|food a fastgrowing james beard awardwinning online food community and crowdsourced and curated recipe hub is currently interviewing full and parttime unpaid interns to work in a small team of editors executives and developers in its new york city headquartersreproducing and or repackaging existing food content for a number of partner sites such as huffington post yahoo buzzfeed and more in their various content management systemsresearching blogs and websites for the provisions by food affiliate programassisting in daytoday affiliate program support such as screening affiliates and assisting in any affiliate inquiriessupporting with pr amp events when neededhelping with office administrative work such as filing mailing and preparing for meetingsworking with developers to document bugs and suggest improvements to the sitesupporting the marketing and executive staff                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|job title itemization review managerlocation fort worth tx department itemization reviewreports to vp operations general descriptionresponsible for the overall aspects of itemization review operations personnel hiring quality control of process workflow monitoring the tracking of and accountability of staff regarding production standards and department expectationsduties and responsibilitiesoversee companys itemization review department in its operationsresponsible for encouraging and reinforcing company culturedevelops processes to better department and implements new procedures protocols works with customer service on elevated issues and provider callsimplements and audits policy in conjunction with policy and payment integrity department monitoring quality and quality control of results for department responsible for ensuring overall metrics are in compliance with management and client expectationsresponsible for human resources matters directly related to department supervised ie interviewing hiring training annual evaluations electronic time cards and addressing personnel issues may create review daily weekly monthly reports invoices logs and expensesadditional duties responsibilities as assigned comply with all safety rules regulations in conjunction with the injury and illness prevention program iipp as well as maintain hipaa complianceoccasional interaction with customers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|job overviewapex is an environmental consulting firm that offers stable leadership and growth and views employees as valuable resources we are seeking a selfmotivated multifaceted accounts payable clerk to join our team in rockville md and become an integral part of our continued success story this position entails processing high volume of invoices and working in a fast pace environment keying and verifying various types of invoices to general ledger accounts and job numbers submitted by vendors and company personnel and calculating balance due to vendor by reviewing history of prior payments made to an account candidate must be able to answer vendor and personnel inquiries via phone or email qualificationsthis position requires a high school diploma and years of relevant work experience keen attention to detail knowledge of commonlyused concepts practices and procedures within the accounting field experience with accounting software proficiency in ms office suite including advanced excel experience and a high degree of professionalismwant to join a team of talented accounting professionals engineers and managers submit your resume for consideration todayurlfeffeaeeffdedbdbfebfebeeaeadabout apexapex is a customerfocused company that delivers environmental health safety and engineering services to over clients across the united states and abroad driven by an entrepreneurial spirit and a dedication to providing responsive costeffective solutions apex has grown rapidly since our founding in working in partnership with our public and private sector clients our team of experts provides services tailored to support each customers unique goals and objectives by blending strong technical skills business acumen and superior customer service we are able to deliver creative solutions that deliver high quality results at low costfrom commercial and industrial firms to construction petroleum and utility companies to financial institutions and government clients apex has extensive experience in a wide variety of industries our corporate professional resume includes proven capabilities in the areas of water resources remediation and restoration assessment and compliance and industrial hygiene among othersranked in the top environmental firms by enr magazine ranked among the top design firms by enr magazine awarded the national environmental excellence award for environmental stewardship by the national association of environmental professionals and selected as a hot firm by the zweig letter come join our award winning teamapex is an entrepreneurial firm and ensuring that our senior managers are able to move unencumbered is our priority we are a successful and growing midsized firm were small enough that our employees still have access to our leadership and its easy for highperformers to be recognized for their contributions and advance without bureaucracy with over office locations were big enough to provide comprehensive environmental consulting and engineering services to our diverse client base and to provide resources to our employees to help in their professional development we offer incentive bonus plans and ownership opportunities for our successful managersapex companies llc is an affirmative action equal opportunity employer|\n",
      "|the customer service associate will be based in phoenix az the right candidate will be an integral part of our talented team supporting our continued growthresponsibilitiesperform various mail center activities sorting metering folding inserting delivery pickup etc lift heavy boxes files or paper when neededmaintain the highest levels of customer care while demonstrating a friendly and cooperative attitudedemonstrate flexibility in satisfying customer demands in a high volume production environmentconsistently adhere to business procedure guidelinesadhere to all safety procedurestake direction from supervisor or site managermaintain all logs and reporting documentation attention to detailparticipate in crosstraining and perform other duties as assigned filing outgoing shipments etc operating mailing copy or scanning equipmentshipping amp receivinghandle timesensitive material like confidential urgent packagesperform other tasks as assignedscanning incoming mail to recipientsperform file purges and pullscreate files and ship filesprovide backfill when neededenter information daily into spreadsheetsidentify charges and match them to billingsort and deliver mail small packages                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "|transferwise is the clever new way to move money between countries cofounded by skypes first employee and backed by some of planets most experienced innovators including sir richard branson and paypal founder peter thiel were disrupting the world of currency amp international money transfer that means flipping a gazillion dollar industry on its head and taking power away from banks and the establishmentbased in old street the hub of londons start up scene were growing at an extraordinary rate with currently just over people strong and handling many millions of pounds daily as it is critical to have the right team behind the vision you can play a key part in building our team of today to during this hyper growth phaseyouve either been working as a sourcer in an internet technology business or at an agency identifying top calibre of candidates predominantly in the business space across europe you will be joining our powerhouse and working closely with our leaders across a range of divisions as well as managing your own pipeline within the fastpace world of a leading startup where no two days are the same                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"description\").show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Data Preparation\n",
    "Prepare the data to analyzed by MLLib:\n",
    "- Tocknize the data\n",
    "- Transform the text in numeric vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |fraudulent|words                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |filtered                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |label|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|food a fastgrowing james beard awardwinning online food community and crowdsourced and curated recipe hub is currently interviewing full and parttime unpaid interns to work in a small team of editors executives and developers in its new york city headquartersreproducing and or repackaging existing food content for a number of partner sites such as huffington post yahoo buzzfeed and more in their various content management systemsresearching blogs and websites for the provisions by food affiliate programassisting in daytoday affiliate program support such as screening affiliates and assisting in any affiliate inquiriessupporting with pr amp events when neededhelping with office administrative work such as filing mailing and preparing for meetingsworking with developers to document bugs and suggest improvements to the sitesupporting the marketing and executive staff|0         |[food, a, fastgrowing, james, beard, awardwinning, online, food, community, and, crowdsourced, and, curated, recipe, hub, is, currently, interviewing, full, and, parttime, unpaid, interns, to, work, in, a, small, team, of, editors, executives, and, developers, in, its, new, york, city, headquartersreproducing, and, or, repackaging, existing, food, content, for, a, number, of, partner, sites, such, as, huffington, post, yahoo, buzzfeed, and, more, in, their, various, content, management, systemsresearching, blogs, and, websites, for, the, provisions, by, food, affiliate, programassisting, in, daytoday, affiliate, program, support, such, as, screening, affiliates, and, assisting, in, any, affiliate, inquiriessupporting, with, pr, amp, events, when, neededhelping, with, office, administrative, work, such, as, filing, mailing, and, preparing, for, meetingsworking, with, developers, to, document, bugs, and, suggest, improvements, to, the, sitesupporting, the, marketing, and, executive, staff]|[food, fastgrowing, james, beard, awardwinning, online, food, community, crowdsourced, curated, recipe, hub, currently, interviewing, full, parttime, unpaid, interns, work, small, team, editors, executives, developers, new, york, city, headquartersreproducing, repackaging, existing, food, content, number, partner, sites, huffington, post, yahoo, buzzfeed, various, content, management, systemsresearching, blogs, websites, provisions, food, affiliate, programassisting, daytoday, affiliate, program, support, screening, affiliates, assisting, affiliate, inquiriessupporting, pr, amp, events, neededhelping, office, administrative, work, filing, mailing, preparing, meetingsworking, developers, document, bugs, suggest, improvements, sitesupporting, marketing, executive, staff]|0.0  |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a ML Pipeline with three fases: Tocknizer, Remove The Stopwords, and Zero Index Label Column\n",
    "\n",
    "# Tokenize\n",
    "regex_tokenizer = RegexTokenizer(inputCol=\"description\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# Remove Stop words\n",
    "remover = StopWordsRemover(inputCol=regex_tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "\n",
    "# Zero Index Label Column\n",
    "indexer = StringIndexer(inputCol=\"fraudulent\", outputCol=\"label\")\n",
    "\n",
    "# Create the Pipeline\n",
    "pipeline = Pipeline(stages=[regex_tokenizer,remover,indexer])\n",
    "data_prep_pl = pipeline.fit(df)\n",
    "\n",
    "# Now call on the Pipeline to get our final df\n",
    "feature_data = data_prep_pl.transform(df)\n",
    "feature_data.show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashing TF\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawfeatures\", numFeatures=20)\n",
    "HTFfeaturizedData = hashingTF.transform(feature_data)\n",
    "\n",
    "# TF-IDF\n",
    "idf = IDF(inputCol=\"rawfeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(HTFfeaturizedData)\n",
    "TFIDFfeaturizedData = idfModel.transform(HTFfeaturizedData)\n",
    "TFIDFfeaturizedData.name = 'TFIDFfeaturizedData'\n",
    "\n",
    "#rename the HTF features to features to be consistent\n",
    "HTFfeaturizedData = HTFfeaturizedData.withColumnRenamed(\"rawfeatures\",\"features\")\n",
    "HTFfeaturizedData.name = 'HTFfeaturizedData' #We will use later for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"filtered\", outputCol=\"features\")\n",
    "model = word2Vec.fit(feature_data)\n",
    "\n",
    "W2VfeaturizedData = model.transform(feature_data)\n",
    "# W2VfeaturizedData.show(1,False)\n",
    "\n",
    "# W2Vec Dataframes typically has negative values so we will correct for that here so that we can use the Naive Bayes classifier\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "# Compute summary statistics and generate MinMaxScalerModel\n",
    "scalerModel = scaler.fit(W2VfeaturizedData)\n",
    "\n",
    "# rescale each feature to range [min, max].\n",
    "scaled_data = scalerModel.transform(W2VfeaturizedData)\n",
    "W2VfeaturizedData = scaled_data.select('fraudulent','description','label','scaledFeatures')\n",
    "W2VfeaturizedData = W2VfeaturizedData.withColumnRenamed('scaledFeatures','features')\n",
    "\n",
    "W2VfeaturizedData.name = 'W2VfeaturizedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>rawfeatures</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food a fastgrowing james beard awardwinning on...</td>\n",
       "      <td>0</td>\n",
       "      <td>[food, a, fastgrowing, james, beard, awardwinn...</td>\n",
       "      <td>[food, fastgrowing, james, beard, awardwinning...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(6.0, 6.0, 8.0, 2.0, 4.0, 4.0, 4.0, 5.0, 5.0, ...</td>\n",
       "      <td>(0.5216208179612858, 0.6445722349011209, 0.407...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job title itemization review managerlocation f...</td>\n",
       "      <td>0</td>\n",
       "      <td>[job, title, itemization, review, managerlocat...</td>\n",
       "      <td>[job, title, itemization, review, managerlocat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(11.0, 4.0, 10.0, 18.0, 8.0, 4.0, 4.0, 7.0, 6....</td>\n",
       "      <td>(0.9563048329290239, 0.42971482326741395, 0.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>job overviewapex is an environmental consultin...</td>\n",
       "      <td>0</td>\n",
       "      <td>[job, overviewapex, is, an, environmental, con...</td>\n",
       "      <td>[job, overviewapex, environmental, consulting,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(10.0, 4.0, 25.0, 24.0, 18.0, 10.0, 11.0, 22.0...</td>\n",
       "      <td>(0.8693680299354762, 0.42971482326741395, 1.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the customer service associate will be based i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, customer, service, associate, will, be, ...</td>\n",
       "      <td>[customer, service, associate, based, phoenix,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(8.0, 4.0, 8.0, 4.0, 2.0, 5.0, 6.0, 4.0, 10.0,...</td>\n",
       "      <td>(0.695494423948381, 0.42971482326741395, 0.407...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description fraudulent  \\\n",
       "0  food a fastgrowing james beard awardwinning on...          0   \n",
       "1  job title itemization review managerlocation f...          0   \n",
       "2  job overviewapex is an environmental consultin...          0   \n",
       "3  the customer service associate will be based i...          0   \n",
       "\n",
       "                                               words  \\\n",
       "0  [food, a, fastgrowing, james, beard, awardwinn...   \n",
       "1  [job, title, itemization, review, managerlocat...   \n",
       "2  [job, overviewapex, is, an, environmental, con...   \n",
       "3  [the, customer, service, associate, will, be, ...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [food, fastgrowing, james, beard, awardwinning...    0.0   \n",
       "1  [job, title, itemization, review, managerlocat...    0.0   \n",
       "2  [job, overviewapex, environmental, consulting,...    0.0   \n",
       "3  [customer, service, associate, based, phoenix,...    0.0   \n",
       "\n",
       "                                         rawfeatures  \\\n",
       "0  (6.0, 6.0, 8.0, 2.0, 4.0, 4.0, 4.0, 5.0, 5.0, ...   \n",
       "1  (11.0, 4.0, 10.0, 18.0, 8.0, 4.0, 4.0, 7.0, 6....   \n",
       "2  (10.0, 4.0, 25.0, 24.0, 18.0, 10.0, 11.0, 22.0...   \n",
       "3  (8.0, 4.0, 8.0, 4.0, 2.0, 5.0, 6.0, 4.0, 10.0,...   \n",
       "\n",
       "                                            features  \n",
       "0  (0.5216208179612858, 0.6445722349011209, 0.407...  \n",
       "1  (0.9563048329290239, 0.42971482326741395, 0.50...  \n",
       "2  (0.8693680299354762, 0.42971482326741395, 1.27...  \n",
       "3  (0.695494423948381, 0.42971482326741395, 0.407...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows the Dataframes after the transformation\n",
    "TFIDFfeaturizedData.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food a fastgrowing james beard awardwinning on...</td>\n",
       "      <td>0</td>\n",
       "      <td>[food, a, fastgrowing, james, beard, awardwinn...</td>\n",
       "      <td>[food, fastgrowing, james, beard, awardwinning...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(6.0, 6.0, 8.0, 2.0, 4.0, 4.0, 4.0, 5.0, 5.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job title itemization review managerlocation f...</td>\n",
       "      <td>0</td>\n",
       "      <td>[job, title, itemization, review, managerlocat...</td>\n",
       "      <td>[job, title, itemization, review, managerlocat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(11.0, 4.0, 10.0, 18.0, 8.0, 4.0, 4.0, 7.0, 6....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>job overviewapex is an environmental consultin...</td>\n",
       "      <td>0</td>\n",
       "      <td>[job, overviewapex, is, an, environmental, con...</td>\n",
       "      <td>[job, overviewapex, environmental, consulting,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(10.0, 4.0, 25.0, 24.0, 18.0, 10.0, 11.0, 22.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the customer service associate will be based i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, customer, service, associate, will, be, ...</td>\n",
       "      <td>[customer, service, associate, based, phoenix,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(8.0, 4.0, 8.0, 4.0, 2.0, 5.0, 6.0, 4.0, 10.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description fraudulent  \\\n",
       "0  food a fastgrowing james beard awardwinning on...          0   \n",
       "1  job title itemization review managerlocation f...          0   \n",
       "2  job overviewapex is an environmental consultin...          0   \n",
       "3  the customer service associate will be based i...          0   \n",
       "\n",
       "                                               words  \\\n",
       "0  [food, a, fastgrowing, james, beard, awardwinn...   \n",
       "1  [job, title, itemization, review, managerlocat...   \n",
       "2  [job, overviewapex, is, an, environmental, con...   \n",
       "3  [the, customer, service, associate, will, be, ...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [food, fastgrowing, james, beard, awardwinning...    0.0   \n",
       "1  [job, title, itemization, review, managerlocat...    0.0   \n",
       "2  [job, overviewapex, environmental, consulting,...    0.0   \n",
       "3  [customer, service, associate, based, phoenix,...    0.0   \n",
       "\n",
       "                                            features  \n",
       "0  (6.0, 6.0, 8.0, 2.0, 4.0, 4.0, 4.0, 5.0, 5.0, ...  \n",
       "1  (11.0, 4.0, 10.0, 18.0, 8.0, 4.0, 4.0, 7.0, 6....  \n",
       "2  (10.0, 4.0, 25.0, 24.0, 18.0, 10.0, 11.0, 22.0...  \n",
       "3  (8.0, 4.0, 8.0, 4.0, 2.0, 5.0, 6.0, 4.0, 10.0,...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTFfeaturizedData.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>food a fastgrowing james beard awardwinning on...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.24843121147833588, 0.357577434919877, 0.481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>job title itemization review managerlocation f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.24557787102800416, 0.43791577504755075, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>job overviewapex is an environmental consultin...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.2555841408061735, 0.3081030392356156, 0.487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the customer service associate will be based i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.28457634526134656, 0.8612176372819632, 0.19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fraudulent                                        description  label  \\\n",
       "0          0  food a fastgrowing james beard awardwinning on...    0.0   \n",
       "1          0  job title itemization review managerlocation f...    0.0   \n",
       "2          0  job overviewapex is an environmental consultin...    0.0   \n",
       "3          0  the customer service associate will be based i...    0.0   \n",
       "\n",
       "                                            features  \n",
       "0  [0.24843121147833588, 0.357577434919877, 0.481...  \n",
       "1  [0.24557787102800416, 0.43791577504755075, 0.3...  \n",
       "2  [0.2555841408061735, 0.3081030392356156, 0.487...  \n",
       "3  [0.28457634526134656, 0.8612176372819632, 0.19...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2VfeaturizedData.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Data\n",
    "\n",
    "Train each classifier algorithm for each vector transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassTrainEval(classifier,features,classes,train,test):\n",
    "\n",
    "    def FindMtype(classifier):\n",
    "        # Intstantiate Model\n",
    "        M = classifier\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "        \n",
    "        return Mtype\n",
    "    \n",
    "    Mtype = FindMtype(classifier)\n",
    "    \n",
    "\n",
    "    def IntanceFitModel(Mtype,classifier,classes,features,train):\n",
    "        \n",
    "        if Mtype == \"OneVsRest\":\n",
    "            # instantiate the base classifier.\n",
    "            lr = LogisticRegression()\n",
    "            # instantiate the One Vs Rest Classifier.\n",
    "            OVRclassifier = OneVsRest(classifier=lr)\n",
    "#             fitModel = OVRclassifier.fit(train)\n",
    "            # Add parameters of your choice here:\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "                .build()\n",
    "            #Cross Validator requires the following parameters:\n",
    "            crossval = CrossValidator(estimator=OVRclassifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 is best practice\n",
    "            # Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            # specify layers for the neural network:\n",
    "            # input layer of size features, two intermediate of features+1 and same size as features\n",
    "            # and output of size number of classes\n",
    "            # Note: crossvalidator cannot be used here\n",
    "            features_count = len(features[0][0])\n",
    "            layers = [features_count, features_count+1, features_count, classes]\n",
    "            MPC_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "            fitModel = MPC_classifier.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2: # These classifiers currently only accept binary classification\n",
    "            print(Mtype,\" could not be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "            return\n",
    "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
    "  \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LogisticRegression\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,20])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"NaiveBayes\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LinearSVC\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "                             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .build())\n",
    "            \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "                             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .build())\n",
    "            \n",
    "            #Cross Validator requires all of the following parameters:\n",
    "            crossval = CrossValidator(estimator=classifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 + is best practice\n",
    "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "    \n",
    "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,train)\n",
    "    \n",
    "    # Set the column names to match the external results dataframe that we will join with later:\n",
    "    columns = ['Classifier', 'Result']\n",
    "    \n",
    "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
    "        Mtype = [Mtype] # make this a list\n",
    "        score = [\"N/A\"]\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "    else:\n",
    "        predictions = fitModel.transform(test)\n",
    "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
    "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "        Mtype = [Mtype] # make this a string\n",
    "        score = [str(accuracy)] #make this a string and convert to a list\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
    "        \n",
    "    return result\n",
    "    #Also returns the fit model important scores or p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql import functions\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Comment out Naive Bayes if your data still contains negative values\n",
    "classifiers = [\n",
    "                LogisticRegression()\n",
    "                ,OneVsRest()\n",
    "               ,LinearSVC()\n",
    "               ,NaiveBayes()\n",
    "               ,RandomForestClassifier()\n",
    "               ,GBTClassifier()\n",
    "               ,DecisionTreeClassifier()\n",
    "               ,MultilayerPerceptronClassifier()\n",
    "              ] \n",
    "\n",
    "featureDF_list = [HTFfeaturizedData,TFIDFfeaturizedData,W2VfeaturizedData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHTFfeaturizedData  Results:\u001b[0m\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |86.82 |\n",
      "|OneVsRest                     |86.77 |\n",
      "|LinearSVC                     |86.77 |\n",
      "|NaiveBayes                    |86.41 |\n",
      "|RandomForestClassifier        |89.36 |\n",
      "|GBTClassifier                 |90.09 |\n",
      "|DecisionTreeClassifier        |87.36 |\n",
      "|MultilayerPerceptronClassifier|87.82 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n",
      "\u001b[1mTFIDFfeaturizedData  Results:\u001b[0m\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |86.82 |\n",
      "|OneVsRest                     |86.77 |\n",
      "|LinearSVC                     |86.77 |\n",
      "|NaiveBayes                    |86.77 |\n",
      "|RandomForestClassifier        |89.36 |\n",
      "|GBTClassifier                 |90.09 |\n",
      "|DecisionTreeClassifier        |87.36 |\n",
      "|MultilayerPerceptronClassifier|87.68 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n",
      "\u001b[1mW2VfeaturizedData  Results:\u001b[0m\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |87.59 |\n",
      "|OneVsRest                     |87.59 |\n",
      "|LinearSVC                     |87.59 |\n",
      "|NaiveBayes                    |87.59 |\n",
      "|RandomForestClassifier        |90.68 |\n",
      "|GBTClassifier                 |90.09 |\n",
      "|DecisionTreeClassifier        |89.09 |\n",
      "|MultilayerPerceptronClassifier|85.05 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for featureDF in featureDF_list:\n",
    "    print('\\033[1m' + featureDF.name,\" Results:\"+ '\\033[0m')\n",
    "    train, test = featureDF.randomSplit([0.7, 0.3],seed = 11)\n",
    "    features = featureDF.select(['features']).collect()\n",
    "    # Learn how many classes there are in order to specify evaluation type based on binary or multi and turn the df into an object\n",
    "    class_count = featureDF.select(countDistinct(\"label\")).collect()\n",
    "    classes = class_count[0][0]\n",
    "\n",
    "    #set up your results table\n",
    "    columns = ['Classifier', 'Result']\n",
    "    vals = [(\"Place Holder\",\"N/A\")]\n",
    "    results = spark.createDataFrame(vals, columns)\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        new_result = ClassTrainEval(classifier,features,classes,train,test)\n",
    "        results = results.union(new_result)\n",
    "    results = results.where(\"Classifier!='Place Holder'\")\n",
    "    print(results.show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
